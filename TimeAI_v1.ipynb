{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oRkbn90EMSif"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "#dimensions: \n",
        "#1: Time (day)\n",
        "#2: Time (time of day - i.e. 1:00 pm) We can possibly do military time for this \n",
        "#3: Output (effectivness) between 1 and 4 "
      ],
      "metadata": {
        "id": "UN2CUy51MYRR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#importing libraries so we can graph and do calculations \n",
        "#Import machine learning techniques as well \n",
        "import pandas as pd \n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns \n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeRegressor \n",
        "from sklearn.preprocessing import PolynomialFeatures \n",
        "from sklearn.pipeline import make_pipeline \n",
        "import os \n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import mean_absolute_error \n",
        "from sklearn.metrics import mean_squared_error \n",
        "import tensorflow as tf \n",
        "print(tf.__version__) "
      ],
      "metadata": {
        "id": "0PA6mxefMtRJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "import datetime\n",
        "import os.path\n",
        "\n",
        "from google.auth.transport.requests import Request\n",
        "from google.oauth2.credentials import Credentials\n",
        "from google_auth_oauthlib.flow import InstalledAppFlow\n",
        "from googleapiclient.discovery import build\n",
        "from googleapiclient.errors import HttpError"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        },
        "id": "-yTYIo3pNT3m",
        "outputId": "d06fcb91-8784-4aca-81e7-9ca19e8f0434"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-a2c870f2e9be>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mcirq_google\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'cirq_google'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "import gspread\n",
        "from google.auth import default\n",
        "creds, _ = default()\n",
        "\n",
        "gc = gspread.authorize(creds)\n",
        "\n",
        "worksheet = gc.open('Final_Proj_Dataset(TimeAI)').sheet1\n",
        "\n",
        "# get_all_values gives a list of rows.\n",
        "rows = worksheet.get_all_values()\n",
        "\n",
        "# Convert to a DataFrame and render.\n",
        "import pandas as pd\n",
        "df =  pd.DataFrame.from_records(rows) "
      ],
      "metadata": {
        "id": "L9oKY1eKOUI8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns = df.iloc[0]\n",
        "df = df.iloc[1:].reset_index(drop=True)"
      ],
      "metadata": {
        "id": "KhAF53ZkTF_K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Task_Class'].value_counts()"
      ],
      "metadata": {
        "id": "71Vsj4CVTFrc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Save the data columns in some variables\n",
        "#for each row add it to the data \n",
        "\n",
        "# time = df[0].astype(float).to_numpy()\n",
        "time = df['Time'].astype(float).to_numpy()\n",
        "day = df['Day'].astype(float).to_numpy()\n",
        "output = df['Time Taken Rating'].astype(float).to_numpy()"
      ],
      "metadata": {
        "id": "pMpTf6QPTKaZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Have to create some type of legend to explore it and explain to users better what is going on \n",
        "#Need to label our points with coordinates so we can make sure our graph is set up correctly\n",
        "#Why are the axis labels reversed? \n",
        "#Have to adjust output scales  \n",
        "\n",
        "fig = plt.figure(figsize=(10, 10))\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "ax.set_title('Day-time-TimeTakenOutput')\n",
        "ax.set_xlabel('day')\n",
        "ax.set_ylabel('time')\n",
        "ax.set_zlabel('output')\n",
        "# ax.set_xlim([0, 1])\n",
        "# ax.set_ylim([0, 1])\n",
        "# ax.set_zlim([0, 1])\n",
        "ax.scatter(day, time, output, c=output, cmap='bwr')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0KQHlO_WTKM_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ax.plot_trisurf(day,time,output,cmap='bwr',edgecolor='none');\n",
        "plt.show() "
      ],
      "metadata": {
        "id": "Im-WAQQdTNyB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df[['Time','Output', 'Day','Task Time Length (in hours) ']]"
      ],
      "metadata": {
        "id": "vm1My0HPTQYL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = df['Time Taken Rating']"
      ],
      "metadata": {
        "id": "HWS6ZjZOTQNj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Xtrain, Xtest,ytrain, ytest = train_test_split(X, y, test_size=0.30, random_state=0)"
      ],
      "metadata": {
        "id": "eqgSommpTQHX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Xtrain.shape"
      ],
      "metadata": {
        "id": "Sj4ahB2bTQA0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Xtest.shape"
      ],
      "metadata": {
        "id": "ag1cOwkyTYsx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ytrain.shape"
      ],
      "metadata": {
        "id": "VTiuiD8DTZ5l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ytest.shape"
      ],
      "metadata": {
        "id": "aDxt5D_ITay7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = LinearRegression() \n",
        "\n",
        "poly_model = make_pipeline(PolynomialFeatures(1), LinearRegression()) \n",
        "poly_model.fit(Xtrain, ytrain)\n",
        "model.fit(Xtrain,ytrain)\n",
        "lypred = model.predict(Xtest)\n",
        "ypred = poly_model.predict(Xtest)\n",
        "mae = mean_absolute_error(ytest,ypred)\n",
        "mse = mean_squared_error(ytest, ypred)\n",
        "lmae = mean_absolute_error(ytest,lypred)\n",
        "lmse = mean_squared_error(ytest,lypred)\n",
        "print('MAE: {:.4f}, MSE: {:.4f}'.format(mae,mse))\n",
        "print('Linear Model: ', 'MAE: {:.4f}, MSE: {:.4f}'.format(lmae,lmse))"
      ],
      "metadata": {
        "id": "SlhHHXBbTcCQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.crosstab(df['Time Taken Rating'], df['Task Time Length (in hours) ']).plot.bar(figsize=(10,10))"
      ],
      "metadata": {
        "id": "YmxFxew_TkFz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observations: \n",
        "- Output -> Time Taken Rating \n",
        "  - Changing the output variable from Output that is measured in 1-4 about general desired output to the time taken rating lowers the error on our prediction. \n",
        "\n",
        "  With Time, Day, Output, Task Time as training variables : \n",
        "\n",
        "Lowest Output as test variable: 22 degrees  \n",
        "- MAE: 27% \n",
        "- MSE: 36% \n",
        "\n",
        "\n",
        "Lowest Time Taken Rating as test variable: 22 degrees  \n",
        "- MAE: 40% \n",
        "- MSE: 66% \n",
        "\n",
        "- When tasks are shorter, it's easier to be efficient, I see from the crosstab that I have more tasks with a short time length and a good Task Time Length Rating"
      ],
      "metadata": {
        "id": "svbdpAozTolG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor"
      ],
      "metadata": {
        "id": "6WtFXLSYTkDS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "estimators = range(1,100)\n",
        "\n",
        "for i in range(len(estimators)): \n",
        "  regressor = RandomForestRegressor(n_estimators=estimators[i],random_state=0) \n",
        "  regressor.fit(Xtrain, ytrain) \n",
        "  ypred = regressor.predict(Xtest)\n",
        "  mae = mean_absolute_error(ytest,ypred)\n",
        "  mse = mean_squared_error(ytest, ypred) \n",
        "  print('MAE: {:.4f}, MSE: {:.4f}'.format(mae,mse))\n"
      ],
      "metadata": {
        "id": "VONfR0szTj_n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "newDf = df[['Time Taken Rating','Output', 'Task Time Length (in hours) ', 'Task_Class']]"
      ],
      "metadata": {
        "id": "7xOy0JmRTj8l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nowDf = pd.get_dummies(newDf) \n",
        "nowDf"
      ],
      "metadata": {
        "id": "Vc2J0GbaTjyI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corr = nowDf.corr() \n",
        "corr"
      ],
      "metadata": {
        "id": "m7xnI_1VT7PD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.heatmap(corr)"
      ],
      "metadata": {
        "id": "yFiEkUpLT909"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential \n",
        "from keras.layers import Dense \n",
        "from sklearn import preprocessing\n",
        "from sklearn.preprocessing import LabelEncoder "
      ],
      "metadata": {
        "id": "13KMMhrHT_tS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lb = LabelEncoder() \n",
        "y = lb.fit_transform(y) "
      ],
      "metadata": {
        "id": "DAIqhfNXT_q0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "min_max_scaler = preprocessing.MinMaxScaler() \n",
        "X_scale = min_max_scaler.fit_transform(X) "
      ],
      "metadata": {
        "id": "4AbKGooMT_ma"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, XvalTest, y_train, yvalTest = train_test_split(X_scale, y, test_size=0.3) "
      ],
      "metadata": {
        "id": "8z9OmQFTT_dC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_val, X_test, Y_val, Y_test = train_test_split(XvalTest,yvalTest, test_size=0.5) "
      ],
      "metadata": {
        "id": "kHmMPl-0T_av"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "annModel = Sequential([\n",
        "        Dense(32, activation='relu', input_shape=(4,)), \n",
        "        Dense(32, activation='relu',),\n",
        "        Dense(32, activation='relu',), \n",
        "        Dense(1, activation='sigmoid'), \n",
        "])\n",
        "\n",
        "annModel.compile(optimizer='sgd', loss='binary_crossentropy', \n",
        "                 metrics=['accuracy']) "
      ],
      "metadata": {
        "id": "4HEU4VKvT_Ym"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train"
      ],
      "metadata": {
        "id": "WjLUkYqrT_WU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hist = annModel.fit(X_train,y_train, batch_size=32, epochs=100, validation_data=(X_val,Y_val)) \n"
      ],
      "metadata": {
        "id": "-EzcV06tT_Tu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "annModel.summary()"
      ],
      "metadata": {
        "id": "M0HQRBTAT_Qa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test"
      ],
      "metadata": {
        "id": "PNADvv0jWlGp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = annModel.predict(X_test) "
      ],
      "metadata": {
        "id": "bnYFCAiLWmRv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y_test"
      ],
      "metadata": {
        "id": "obJ24M7TWoT3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred"
      ],
      "metadata": {
        "id": "it81q5v3WoRW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score \n",
        "annModel.evaluate(X_test,Y_test)[1]"
      ],
      "metadata": {
        "id": "HQ9xpkUTWqys"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(hist.history['loss']) \n",
        "plt.plot(hist.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Val'], loc='upper right')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "KEFXzaKWWqwn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(hist.history['accuracy'])\n",
        "plt.plot(hist.history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Val'], loc='lower right')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "SpteQNgfWvcP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YZEHDJNxWvZU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}